{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuaQFlTDeGE8",
        "outputId": "f7e511d4-0f2c-41b0-b2f7-a82ac66581c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 348 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 61.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 69.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "mL0GerRHPLhU",
        "outputId": "6d891b03-d704-4897-8d72-f2e4e1f476f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import optuna\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from IPython.display import clear_output\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim\n",
        "\n",
        "import antidistil\n",
        "import pipeline\n",
        "import consts\n",
        "from importlib import reload\n",
        "import plot\n",
        "import json\n",
        "reload(plot)\n",
        "reload(antidistil)\n",
        "reload(pipeline)\n",
        "reload(consts)\n",
        "plot.prepare_for_plots()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader = pipeline.get_data()"
      ],
      "metadata": {
        "id": "pt3eOKJuPZbo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_antidistill_loop(l1, l2, l3, l4):\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for i in range(consts.num_repeats):\n",
        "        clear_output()\n",
        "        print(f\"Model {i+1}\\n-------------------------------\"\n",
        "                          \"\\n-------------------------------\")\n",
        "\n",
        "        torch.manual_seed(i)\n",
        "\n",
        "        teacher = pipeline.make_teacher_model()\n",
        "        teacher.load_state_dict(torch.load(pipeline.get_path()+f'/teacher_5cl_{i}.pt'))\n",
        "        model = antidistil.make_student_model()\n",
        "\n",
        "        mask = torch.tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.float).to(consts.device)\n",
        "        \n",
        "        loss_fn = antidistil.altidistill_loss\n",
        "        optimizer = optim.Adam(model.parameters(), lr=consts.student_5_antidistil_learning_rate)\n",
        "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
        "\n",
        "        lambdas = [l1, l2, l3, l4]\n",
        "        \n",
        "        for epoch in range(10):\n",
        "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "\n",
        "            pipeline.antidistil_loop(teacher, model, lambdas, mask, train_dataloader, \n",
        "                                    loss_fn, optimizer, scheduler, noise_dist='uniform', noise_eps=1e-1)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=consts.student_5_learning_rate)    \n",
        "\n",
        "        mask = torch.ones(10).to(consts.device)\n",
        "\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(10):\n",
        "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "\n",
        "            pipeline.train_loop(model, history, mask, train_dataloader, loss_fn, optimizer)\n",
        "            pipeline.test_loop(model, history, mask, test_dataloader, loss_fn)\n",
        "\n",
        "        pipeline.test_loop_fsgm(model, history, mask, test_dataloader, loss_fn, consts.fsgm_eps)\n",
        "        pipeline.test_loop_noise(model, history, mask, test_dataloader, consts.noise_eps)\n",
        "\n",
        "    return np.array(history['fsgm_noise_acc']).mean(axis=0)[-1]"
      ],
      "metadata": {
        "id": "1wNLbeijPu8Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    l1 = trial.suggest_float('l1', 0, 1)\n",
        "    l2 = trial.suggest_float('l2', 0, 1)\n",
        "    l3 = trial.suggest_float('l3', 0, 1)\n",
        "    l4 = trial.suggest_float('l4', 0, 1)\n",
        "    \n",
        "    acc = train_antidistill_loop(l1, l2, l3, l4)\n",
        "\n",
        "    return acc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "swCB6zNHN5m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trials"
      ],
      "metadata": {
        "id": "TDjN9peafoIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = optuna.importance.get_param_importances(study)\n",
        "best_params"
      ],
      "metadata": {
        "id": "KuLoi6DbJF0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "for i in range(consts.num_repeats):\n",
        "    clear_output()\n",
        "    print(f\"Model {i+1}\\n-------------------------------\"\n",
        "                      \"\\n-------------------------------\")\n",
        "\n",
        "    torch.manual_seed(i)\n",
        "\n",
        "    teacher = pipeline.make_teacher_model()\n",
        "    teacher.load_state_dict(torch.load(pipeline.get_path()+f'/teacher_5cl_{i}.pt'))\n",
        "    model = antidistil.make_student_model()\n",
        "\n",
        "    mask = torch.tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype=torch.float).to(consts.device)\n",
        "    \n",
        "    loss_fn = antidistil.altidistill_loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=consts.student_5_antidistil_learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
        "\n",
        "    lambdas = [value for _, value in best_params.items()]\n",
        "    \n",
        "    for epoch in range(consts.student_5_antidistil_epochs):\n",
        "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "\n",
        "        pipeline.antidistil_loop(teacher, model, lambdas, mask, train_dataloader, \n",
        "                                loss_fn, optimizer, scheduler, noise_dist='uniform', noise_eps=1e-1)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=consts.student_5_learning_rate)    \n",
        "\n",
        "    mask = torch.ones(10).to(consts.device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(consts.student_5_training_epochs):\n",
        "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "\n",
        "        pipeline.train_loop(model, history, mask, train_dataloader, loss_fn, optimizer)\n",
        "        pipeline.test_loop(model, history, mask, test_dataloader, loss_fn)\n",
        "\n",
        "    pipeline.test_loop_fsgm(model, history, mask, test_dataloader, loss_fn, consts.fsgm_eps)\n",
        "    pipeline.test_loop_noise(model, history, mask, test_dataloader, consts.noise_eps)"
      ],
      "metadata": {
        "id": "lVqkyik3GaWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reload(plot)\n",
        "plot.prepare_for_plots()\n",
        "plot.plot_variance([history], np.arange(1, consts.student_5_training_epochs + 1),\n",
        "                   ['From scratch'], 'val_acc', \n",
        "                    'Epoch', 'Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnKhovdoV7vD",
        "outputId": "0a71d6ab-5a06-4552-9976-ea21c77b3133"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your plot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reload(plot)\n",
        "plot.prepare_for_plots()\n",
        "plot.plot_variance([history], consts.fsgm_eps,\n",
        "                   ['From scratch'], 'fsgm_noise_acc', \n",
        "                    'FSGM eps', 'Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_dacsQ5XNLe",
        "outputId": "1c30d8f0-d6ba-490c-92fb-559611cab78c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your plot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reload(plot)\n",
        "plot.prepare_for_plots()\n",
        "plot.plot_variance([history], consts.fsgm_eps,\n",
        "                   ['From scratch'], 'param_noise_acc', \n",
        "                    'Param noise eps', 'Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zO4m1hdXPP3",
        "outputId": "02a33ba7-1593-4349-dd1e-e9ae6f1c86ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your plot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pipeline.get_path()+'/history_best_antidistill_with_L4.json', 'w') as out:\n",
        "    out.write(json.dumps(history))"
      ],
      "metadata": {
        "id": "RBtDSC1EZgOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}